{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7de01895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "# Import TensorFlow >= 1.9 and enable eager execution\n",
    "import tensorflow as tf\n",
    "\n",
    "# tf.enable_eager_execution()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import unicodedata\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c04bda3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-361b628373b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword_pairs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'<start> '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' <end>'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'<start> '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' <end>'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_pairs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "with open('language_data.csv','r',encoding='utf8') as k:\n",
    "        data = k.read()\n",
    "uncleaned_data = data.split('\\n')\n",
    "word_pairs = []\n",
    "for sentence in uncleaned_data:\n",
    "    word_pairs.append(sentence.split(','))\n",
    "for word in word_pairs:\n",
    "    word[0] = '<start> ' + word[0] + ' <end>'\n",
    "    word[1] = '<start> ' + word[1] + ' <end>'\n",
    "print(word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfa553ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path):\n",
    "    with open(path,'r',encoding='utf8') as k:\n",
    "        data = k.read()\n",
    "    uncleaned_data = data.split('\\n')[:150]\n",
    "    word_pairs = []\n",
    "    for sentence in uncleaned_data:\n",
    "        a = []\n",
    "        a.append(sentence.split('\\t')[:-1][0])\n",
    "        a.append(sentence.split('\\t')[:-1][1])\n",
    "        word_pairs.append(a)\n",
    "    for word in word_pairs:\n",
    "        word[0] = '<start> ' + word[0] + ' <end>'\n",
    "        word[1] = '<start> ' + word[1] + ' <end>'\n",
    "    return word_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a3e859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageIndex():\n",
    "  def __init__(self, lang):\n",
    "    self.lang = lang\n",
    "    self.word2idx = {}\n",
    "    self.idx2word = {}\n",
    "    self.vocab = set()\n",
    "    \n",
    "    self.create_index()\n",
    "    \n",
    "  def create_index(self):\n",
    "    for phrase in self.lang:\n",
    "        self.vocab.update(phrase.split(' '))\n",
    "    \n",
    "    self.vocab = sorted(self.vocab)\n",
    "    \n",
    "    self.word2idx['<pad>'] = 0\n",
    "    for index, word in enumerate(self.vocab):\n",
    "      self.word2idx[word] = index + 1\n",
    "    \n",
    "    for word, index in self.word2idx.items():\n",
    "      self.idx2word[index] = word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6507694b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_length(tensor):\n",
    "    return max(len(t) for t in tensor)\n",
    "\n",
    "\n",
    "def load_dataset(path, num_examples):\n",
    "    # creating cleaned input, output pairs\n",
    "    pairs = create_dataset(path)\n",
    "\n",
    "    # index language using the class defined above    \n",
    "    inp_lang = LanguageIndex(en for en, kn in pairs)\n",
    "    targ_lang = LanguageIndex(kn for en, kn in pairs)\n",
    "    \n",
    "    # Vectorize the input and target languages\n",
    "    \n",
    "    # Spanish sentences\n",
    "    input_tensor = [[inp_lang.word2idx[s] for s in en.split(' ')] for en, kn in pairs]\n",
    "    \n",
    "    # English sentences\n",
    "    target_tensor = [[targ_lang.word2idx[s] for s in kn.split(' ')] for en, kn in pairs]\n",
    "    \n",
    "    # Calculate max_length of input and output tensor\n",
    "    # Here, we'll set those to the longest sentence in the dataset\n",
    "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
    "    \n",
    "    # Padding the input and output tensor to the maximum length\n",
    "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
    "                                                                 maxlen=max_length_inp,\n",
    "                                                                 padding='post')\n",
    "    \n",
    "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
    "                                                                  maxlen=max_length_tar, \n",
    "                                                                  padding='post')\n",
    "    \n",
    "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37cb274d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 150\n",
    "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset('C:/Users/Sumukh Kashi/Downloads/kan.txt', num_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2375029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 120, 30, 30)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating training and validation sets using an 80-20 split\n",
    "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.20)\n",
    "\n",
    "# Show length\n",
    "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e9ab50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 14), (None, 11)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "BUFFER_SIZE = len(input_tensor_train)\n",
    "BATCH_SIZE = 8\n",
    "embedding_dim = 256\n",
    "units = 1024\n",
    "vocab_inp_size = len(inp_lang.word2idx)\n",
    "vocab_tar_size = len(targ_lang.word2idx)\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7fb12943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "  # If you have a GPU, we recommend using CuDNNGRU(provides a 3x speedup than GRU)\n",
    "  # the code automatically does that.\n",
    "    return tf.keras.layers.GRU(units, \n",
    "                               return_sequences=True, \n",
    "                               return_state=True, \n",
    "                               recurrent_activation='sigmoid', \n",
    "                               recurrent_initializer='he_uniform') #changed from glorot_uniform for better distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cf8dc9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "        \n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state = hidden)        \n",
    "        return output, state\n",
    "    \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9123be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "        # used for attention\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, x, hidden, enc_output):\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "        \n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        \n",
    "        # score shape == (batch_size, max_length, hidden_size)\n",
    "        score = tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
    "        #Adding extra softmax layer\n",
    "        #score = tf.nn.softmax(self.W1(enc_output) + self.W2(hidden_with_time_axis))\n",
    "        \n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        #attention_weights = tf.nn.relu(self.V(score))\n",
    "        attention_weights = tf.nn.softmax(self.V(score), axis=1)\n",
    "        \n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        \n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "        \n",
    "        # passing the concatenated vector to the GRU\n",
    "        output, state = self.gru(x)\n",
    "        \n",
    "        # output shape == (batch_size * max_length, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "        \n",
    "        # output shape == (batch_size * max_length, vocab)\n",
    "        x = self.fc(output)\n",
    "        \n",
    "        return x, state, attention_weights\n",
    "        \n",
    "    def initialize_hidden_state(self):\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8e322937",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
    "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5005967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam()\n",
    "\n",
    "\n",
    "def loss_function(real, pred):\n",
    "  mask = 1 - np.equal(real, 0)\n",
    "  loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "  return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "450a2b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 2.7917\n",
      "Epoch 1 Loss 0.3009\n",
      "Time taken for 1 epoch 11.960335493087769 sec\n",
      "\n",
      "Epoch 2 Batch 0 Loss 2.6662\n",
      "Epoch 2 Loss 0.2691\n",
      "Time taken for 1 epoch 11.630171775817871 sec\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.3650\n",
      "Epoch 3 Loss 0.2535\n",
      "Time taken for 1 epoch 11.553632497787476 sec\n",
      "\n",
      "Epoch 4 Batch 0 Loss 2.5109\n",
      "Epoch 4 Loss 0.2406\n",
      "Time taken for 1 epoch 11.592616558074951 sec\n",
      "\n",
      "Epoch 5 Batch 0 Loss 2.1054\n",
      "Epoch 5 Loss 0.2261\n",
      "Time taken for 1 epoch 11.617213010787964 sec\n",
      "\n",
      "Epoch 6 Batch 0 Loss 2.3305\n",
      "Epoch 6 Loss 0.2156\n",
      "Time taken for 1 epoch 11.540555238723755 sec\n",
      "\n",
      "Epoch 7 Batch 0 Loss 2.1154\n",
      "Epoch 7 Loss 0.2067\n",
      "Time taken for 1 epoch 11.595233917236328 sec\n",
      "\n",
      "Epoch 8 Batch 0 Loss 2.1306\n",
      "Epoch 8 Loss 0.1961\n",
      "Time taken for 1 epoch 11.85274887084961 sec\n",
      "\n",
      "Epoch 9 Batch 0 Loss 1.6539\n",
      "Epoch 9 Loss 0.1787\n",
      "Time taken for 1 epoch 11.659924030303955 sec\n",
      "\n",
      "Epoch 10 Batch 0 Loss 1.6608\n",
      "Epoch 10 Loss 0.1618\n",
      "Time taken for 1 epoch 11.581582069396973 sec\n",
      "\n",
      "Epoch 11 Batch 0 Loss 1.9243\n",
      "Epoch 11 Loss 0.1443\n",
      "Time taken for 1 epoch 11.576183319091797 sec\n",
      "\n",
      "Epoch 12 Batch 0 Loss 1.1534\n",
      "Epoch 12 Loss 0.1261\n",
      "Time taken for 1 epoch 11.62830662727356 sec\n",
      "\n",
      "Epoch 13 Batch 0 Loss 1.0761\n",
      "Epoch 13 Loss 0.1109\n",
      "Time taken for 1 epoch 11.576735734939575 sec\n",
      "\n",
      "Epoch 14 Batch 0 Loss 1.0563\n",
      "Epoch 14 Loss 0.0972\n",
      "Time taken for 1 epoch 11.528461694717407 sec\n",
      "\n",
      "Epoch 15 Batch 0 Loss 0.7529\n",
      "Epoch 15 Loss 0.0779\n",
      "Time taken for 1 epoch 11.786310911178589 sec\n",
      "\n",
      "Epoch 16 Batch 0 Loss 0.6694\n",
      "Epoch 16 Loss 0.0648\n",
      "Time taken for 1 epoch 12.361970901489258 sec\n",
      "\n",
      "Epoch 17 Batch 0 Loss 0.4508\n",
      "Epoch 17 Loss 0.0540\n",
      "Time taken for 1 epoch 11.60830545425415 sec\n",
      "\n",
      "Epoch 18 Batch 0 Loss 0.3902\n",
      "Epoch 18 Loss 0.0445\n",
      "Time taken for 1 epoch 11.752195596694946 sec\n",
      "\n",
      "Epoch 19 Batch 0 Loss 0.3532\n",
      "Epoch 19 Loss 0.0391\n",
      "Time taken for 1 epoch 11.567544221878052 sec\n",
      "\n",
      "Epoch 20 Batch 0 Loss 0.2925\n",
      "Epoch 20 Loss 0.0322\n",
      "Time taken for 1 epoch 12.036052465438843 sec\n",
      "\n",
      "Epoch 21 Batch 0 Loss 0.2465\n",
      "Epoch 21 Loss 0.0274\n",
      "Time taken for 1 epoch 11.585303783416748 sec\n",
      "\n",
      "Epoch 22 Batch 0 Loss 0.1618\n",
      "Epoch 22 Loss 0.0237\n",
      "Time taken for 1 epoch 11.548937320709229 sec\n",
      "\n",
      "Epoch 23 Batch 0 Loss 0.1782\n",
      "Epoch 23 Loss 0.0221\n",
      "Time taken for 1 epoch 12.230364084243774 sec\n",
      "\n",
      "Epoch 24 Batch 0 Loss 0.2162\n",
      "Epoch 24 Loss 0.0218\n",
      "Time taken for 1 epoch 11.612716674804688 sec\n",
      "\n",
      "Epoch 25 Batch 0 Loss 0.0918\n",
      "Epoch 25 Loss 0.0171\n",
      "Time taken for 1 epoch 11.717589855194092 sec\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 25\n",
    "loss_list = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for (batch, (inp, targ)) in enumerate(dataset):\n",
    "        loss = 0\n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            enc_output, enc_hidden = encoder( inp,hidden)\n",
    "            \n",
    "            dec_hidden = enc_hidden\n",
    "            \n",
    "            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)       \n",
    "            \n",
    "            # Teacher forcing - feeding the target as the next input\n",
    "            for t in range(1, targ.shape[1]):\n",
    "                # passing enc_output to the decoder\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                loss += loss_function(targ[:, t], predictions)\n",
    "                \n",
    "                # using teacher forcing\n",
    "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
    "        \n",
    "        total_loss += (loss / int(targ.shape[1]))\n",
    "        \n",
    "        variables = encoder.variables + decoder.variables\n",
    "        \n",
    "        gradients = tape.gradient(loss, variables)\n",
    "      \n",
    "        optimizer.apply_gradients(zip(gradients, variables), tf.optimizers.SGD())\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                                         batch,\n",
    "                                                         loss.numpy() / int(targ.shape[1])))\n",
    "    loss_list.append(loss.numpy() / int(targ.shape[1]))\n",
    "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
    "                                        total_loss/len(input_tensor)))\n",
    "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d510f316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# importing the required module\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "a = []\n",
    "# x axis values\n",
    "for i in range(EPOCHS):\n",
    "    a.append(i)\n",
    "x = a\n",
    "# corresponding y axis values\n",
    "\n",
    "y = loss_list\n",
    "\n",
    "# plotting the points\n",
    "plt.plot(x, y)\n",
    "\n",
    "# naming the x axis\n",
    "plt.xlabel('Epoch')\n",
    "# naming the y axis\n",
    "plt.ylabel('Validation Loss')\n",
    "\n",
    "# giving a title to my graph\n",
    "plt.title('Validation Loss')\n",
    "\n",
    "# function to show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f2b7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "# Converts the unicode file to ascii\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "\n",
    "def preprocess_sentence(w):\n",
    "#     w = w.lower()\n",
    "    \n",
    "#     # creating a space between a word and the punctuation following it\n",
    "#     # eg: \"he is a boy.\" => \"he is a boy .\" \n",
    "#     # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n",
    "#     w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\n",
    "#     w = re.sub(r'[\" \"]+', \" \", w)\n",
    "    \n",
    "#     # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
    "#     w = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", w)\n",
    "    \n",
    "#     w = w.rstrip().strip()\n",
    "    \n",
    "    # adding a start and an end token to the sentence\n",
    "    # so that the model know when to start and stop predicting.\n",
    "    w = '<start> ' + w + ' <end>'\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d58eb927",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "    \n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang.word2idx[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "    \n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "        \n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.random.categorical(tf.exp(predictions), num_samples=1)[0][0].numpy()\n",
    "\n",
    "        result += targ_lang.idx2word[predicted_id] + ' '\n",
    "\n",
    "        if targ_lang.idx2word[predicted_id] == '<end>':\n",
    "            return result, sentence, attention_plot\n",
    "        \n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff923610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "    \n",
    "    fontdict = {'fontsize': 14}\n",
    "    \n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "857c54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
    "        \n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "    \n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "605c2daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: <start> How's your family? <end>\n",
      "Predicted translation: ನಿಮ್ಮ ಮನೇಲಿ ಹೆಂಗಿದ್ದಾರೆ <end> \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-219babc300ac>:9: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
      "<ipython-input-23-219babc300ac>:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3240 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3263 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3246 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3277 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3271 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3250 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3257 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3270 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3202 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3223 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3238 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3262 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:238: RuntimeWarning: Glyph 3248 missing from current font.\n",
      "  font.set_text(s, 0.0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3240 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3263 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3246 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3277 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3271 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3250 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3257 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3270 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3202 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3223 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3238 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3262 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n",
      "C:\\Anaconda\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:201: RuntimeWarning: Glyph 3248 missing from current font.\n",
      "  font.set_text(s, 0, flags=flags)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "translate(\"How's your family?\", encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "064db9c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-d56dd3727c3e>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-d56dd3727c3e>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    pip install d2l\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "pip install d2l\n",
    "\n",
    "import tensorflow as tf\n",
    "from d2l import tensorflow as d2l\n",
    "\n",
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = d2l.load_data_time_machine(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2283329b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Anaconda\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "C:\\Anaconda\\lib\\site-packages\\nltk\\translate\\bleu_score.py:516: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "reference = [['ಟಾಮ್','ಎಂದಾದರೂ','ನಿನ್ನನ್ನು','ನೋಯಿಸಿದ್ದಾನೆಯೇ?']]\n",
    "hypothesis1 = ['ಟಾಮ್','ನಿನ್ನನ್ನು','ಯಾವಾಗಲಾದರೂ','ನೋಯಿಸಿದ್ದಾನಾ?']\n",
    "\n",
    "score = sentence_bleu(reference, hypothesis1, weights=(1, 0, 0, 0))\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a73a7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
